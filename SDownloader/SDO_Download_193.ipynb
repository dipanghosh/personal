{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "date = 20110105\n",
    "\n",
    "headers={'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/5                                                                                    37.11',\n",
    "   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "   'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "   'Accept-Encoding': 'none',\n",
    "   'Accept-Language': 'en-US,en;q=0.8',\n",
    "   'Connection': 'keep-alive'}\n",
    "\n",
    "domain = \"https://sdo.gsfc.nasa.gov/assets/img/browse/\"\n",
    "\n",
    "def get_day_images(day_date, retrycount = 0):\n",
    "    datetime_object = datetime.strptime(str(day_date), \"%Y%m%d\")\n",
    "    targetdate = (datetime.strftime(datetime_object, '%Y%%2F%m%%2F%d'))\n",
    "\n",
    "    \n",
    "    URL = domain + \"index.php?b=\" + targetdate\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(URL) \n",
    "        soup = BeautifulSoup(r.content, features=\"html.parser\") \n",
    "        images = [img.get('href') for img in soup.findAll('a') if (\"4096_0193.jpg\" in img.get('href'))]\n",
    "        return images\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print (e)\n",
    "        retrycount += 1\n",
    "        if retrycount < 3:\n",
    "            print(\"Retrying {}, retry #{}\".format(day_date, retrycount))\n",
    "            return get_day_images(day_date, retrycount)\n",
    "        else:\n",
    "            return None    \n",
    "\n",
    "def download_img(url_address, filename):\n",
    "    request_=urllib.request.Request(url_address,None,headers) #The assembled request\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request_)# store the response\n",
    "        f = open(str(filename),'wb')\n",
    "        f.write(response.read())\n",
    "        f.close()\n",
    "    except:\n",
    "        print (\"Retrying \" + url_address)\n",
    "        download_img (url_address, filename)\n",
    "        \n",
    "    #create a new file and write the image\n",
    "    \n",
    "def download_img_new(url_address, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        response = requests.get(url_address, stream=True)\n",
    "\n",
    "        if not response.ok:\n",
    "            print (\"Retrying \" + url_address)\n",
    "            download_img (url_address, filename)\n",
    "\n",
    "        for block in response.iter_content(1024):\n",
    "            if not block:\n",
    "                break\n",
    "\n",
    "            handle.write(block)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(start_date, end_date):\n",
    "    sdate = datetime.strptime(str(start_date), \"%Y%m%d\")   # start date\n",
    "    edate = datetime.strptime(str(end_date), \"%Y%m%d\")   # end date\n",
    "\n",
    "    delta = edate - sdate       # as timedelta\n",
    "\n",
    "    dates = []\n",
    "    for i in range(delta.days + 1):\n",
    "        day = sdate + timedelta(days=i)\n",
    "        dates.append(datetime.strftime(day, '%Y%m%d'))\n",
    "    return dates\n",
    "\n",
    "\n",
    "def download_date_images(date):\n",
    "    directory = str(date)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    imagelinks = get_day_images(date)\n",
    "    if imagelinks:\n",
    "        for image in tqdm(imagelinks):\n",
    "            image_url = domain + image\n",
    "            image_name = str(date) + \"\\\\\" + image_url.split('/')[-1]\n",
    "            if not os.path.isfile(image_name):\n",
    "                download_img(image_url, image_name)\n",
    "            else:\n",
    "                print(\"File Exists, skipped\")\n",
    "    else:\n",
    "        print(\"Error Upstream, retrying did not fix \" + str(date))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images from 20110823\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbef95db22794ebcb81f907019e11712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=93.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "File Exists, skipped\n",
      "Retrying https://sdo.gsfc.nasa.gov/assets/img/browse/2011/08/23/20110823_231132_4096_0193.jpg\n",
      "\n",
      "Downloading images from 20110824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0538efa1478b41f7b78e1b03b770afde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=96.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for date in get_dates(20110823, 20111231):\n",
    "    print (\"Downloading images from \" + date)\n",
    "    download_date_images(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_day_images(20110101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20110619 not done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
